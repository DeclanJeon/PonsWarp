/// <reference lib="webworker" />
declare const self: DedicatedWorkerGlobalScope;

import { Zip, ZipPassThrough, AsyncZipDeflate } from 'fflate';

// ğŸ” ì•”í˜¸í™” ê´€ë ¨ ìƒìˆ˜ ë° í•¨ìˆ˜ (ì›Œì»¤ í™˜ê²½ìš©)
const ALGORITHM = 'AES-GCM';
const KEY_LENGTH = 256;

// ì›Œì»¤ í™˜ê²½ì—ì„œ ì•”í˜¸í™” ìœ í‹¸ë¦¬í‹°
class WorkerEncryptionService {
  /**
   * Base64 ë¬¸ìì—´ì—ì„œ CryptoKey ê°ì²´ ë³µì›
   */
  public static async importKey(base64Key: string): Promise<CryptoKey> {
    const raw = this.base64ToArrayBuffer(base64Key);
    return await self.crypto.subtle.importKey(
      'raw',
      raw,
      ALGORITHM,
      false,
      ['encrypt', 'decrypt']
    );
  }

  /**
   * ì²­í¬ ì•”í˜¸í™” (IVëŠ” ì²­í¬ ì‹œí€€ìŠ¤ ë²ˆí˜¸ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ì˜¤ë²„í—¤ë“œ ì œê±°)
   */
  public static async encryptChunk(
    key: CryptoKey,
    data: ArrayBuffer,
    chunkIndex: number
  ): Promise<ArrayBuffer> {
    const iv = this.generateIV(chunkIndex);
    return await self.crypto.subtle.encrypt(
      { name: ALGORITHM, iv: iv as BufferSource },
      key,
      data
    );
  }

  // ì²­í¬ ì¸ë±ìŠ¤ë¥¼ 12byte IVë¡œ ë³€í™˜ (Deterministic IV)
  private static generateIV(counter: number): Uint8Array {
    const iv = new Uint8Array(12);
    const view = new DataView(iv.buffer);
    // ë§ˆì§€ë§‰ 4ë°”ì´íŠ¸ì— ì²­í¬ ì¸ë±ìŠ¤ ê¸°ë¡ (40ì–µ ê°œ ì²­í¬ê¹Œì§€ ì§€ì›)
    view.setUint32(8, counter, false); // Big-Endian
    return iv;
  }

  private static base64ToArrayBuffer(base64: string): ArrayBuffer {
    const b64 = base64.replace(/-/g, '+').replace(/_/g, '/');
    const binary = self.atob(b64);
    const bytes = new Uint8Array(binary.length);
    for (let i = 0; i < binary.length; i++) {
      bytes[i] = binary.charCodeAt(i);
    }
    return bytes.buffer;
  }
}

// ğŸš€ [ì‹ ê·œ] íŒŒì¼ í™•ì¥ì ê¸°ë°˜ ì••ì¶• í•„ìš” ì—¬ë¶€ íŒë‹¨
function isCompressibleFile(filename: string): boolean {
  const ext = filename.split('.').pop()?.toLowerCase();
  // ì´ë¯¸ ì••ì¶•ëœ í¬ë§·ë“¤ì€ CPU ë‚­ë¹„ë¥¼ ë§‰ê¸° ìœ„í•´ ì••ì¶•í•˜ì§€ ì•ŠìŒ
  const nonCompressibleExts = new Set([
    'zip', 'rar', '7z', 'gz', 'tar', // ì•„ì¹´ì´ë¸Œ
    'jpg', 'jpeg', 'png', 'gif', 'webp', // ì´ë¯¸ì§€
    'mp4', 'mkv', 'avi', 'mov', 'webm', // ë¹„ë””ì˜¤
    'mp3', 'wav', 'ogg', 'flac', // ì˜¤ë””ì˜¤
    'pdf', 'docx', 'xlsx', 'pptx' // ë¬¸ì„œ (ì´ë¯¸ ì••ì¶•ë¨)
  ]);
  return !ext || !nonCompressibleExts.has(ext);
}

// ğŸš€ [ì‹ ê·œ] ì „ì†¡ ë‚´ì—­ ë²„í¼ (ì¬ì „ì†¡ìš©)
class HistoryBuffer {
  private history: Map<number, Uint8Array> = new Map(); // Offset -> Data
  private offsets: number[] = []; // ìˆœì„œ ì¶”ì ìš© (LRU)
  private currentSize = 0;
  private readonly MAX_SIZE = 128 * 1024 * 1024; // 128MB íˆìŠ¤í† ë¦¬ (ì•½ 1ì´ˆ ë¶„ëŸ‰)

  public add(offset: number, data: Uint8Array) {
    // ì´ë¯¸ ìˆìœ¼ë©´ ë¬´ì‹œ
    if (this.history.has(offset)) return;

    this.history.set(offset, data);
    this.offsets.push(offset);
    this.currentSize += data.byteLength;

    // ìš©ëŸ‰ ê´€ë¦¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ)
    while (this.currentSize > this.MAX_SIZE && this.offsets.length > 0) {
      const oldOffset = this.offsets.shift()!;
      const oldData = this.history.get(oldOffset);
      if (oldData) {
        this.currentSize -= oldData.byteLength;
        this.history.delete(oldOffset);
      }
    }
  }

  public get(offset: number): Uint8Array | undefined {
    return this.history.get(offset);
  }

  public clear() {
    this.history.clear();
    this.offsets = [];
    this.currentSize = 0;
  }
}

const historyBuffer = new HistoryBuffer();

// ğŸš€ [ì‹ ê·œ] ê¸´ê¸‰ ì¬ì „ì†¡ í
const priorityQueue: ArrayBuffer[] = [];

// WASM ëª¨ë“ˆ ë¡œë”© ì œê±° (fflate ì‚¬ìš©)

// ============================================================================
// ğŸš€ Sender Worker V3 (fflate Powered)
// - Core: fflate ZIP streaming
// - Features: Real ZIP format, Backpressure, Memory efficient
// ============================================================================

const CHUNK_SIZE_MIN = 16 * 1024;
const CHUNK_SIZE_MAX = 64 * 1024;
let CHUNK_SIZE = CHUNK_SIZE_MAX;

const BUFFER_SIZE = 8 * 1024 * 1024; // 8MB sender ë²„í¼
const POOL_SIZE = 128; // í’€ ì‚¬ì´ì¦ˆ
const PREFETCH_BATCH = 16; 

// ZIP ë°±í”„ë ˆì…” ì„ê³„ê°’
const ZIP_QUEUE_HIGH_WATER_MARK = 32 * 1024 * 1024; 
const ZIP_QUEUE_LOW_WATER_MARK = 8 * 1024 * 1024;   

interface AdaptiveConfig {
  chunkSize: number;
  prefetchBatch: number;
  enableAdaptive: boolean;
}

// --- ChunkPool & DoubleBuffer (ê¸°ì¡´ ë¡œì§ ìœ ì§€) ---
class ChunkPool {
  private pool: Uint8Array[] = [];
  private readonly chunkSize: number;
  private readonly maxPoolSize: number;

  constructor(chunkSize: number, maxPoolSize: number) {
    this.chunkSize = chunkSize + 18;
    this.maxPoolSize = maxPoolSize;
  }

  acquire(): Uint8Array {
    return this.pool.pop() || new Uint8Array(this.chunkSize);
  }

  release(buffer: Uint8Array) {
    if (this.pool.length < this.maxPoolSize) {
      this.pool.push(buffer);
    }
  }

  clear() {
    this.pool = [];
  }
}

class DoubleBuffer {
  private bufferA: ArrayBuffer[] = [];
  private bufferB: ArrayBuffer[] = [];
  private sizeA = 0;
  private sizeB = 0;
  private activeBuffer: 'A' | 'B' = 'A';
  private readonly maxSize: number;

  constructor(maxSize: number) {
    this.maxSize = maxSize;
  }

  getActiveSize(): number {
    return this.activeBuffer === 'A' ? this.sizeA : this.sizeB;
  }

  getInactiveSize(): number {
    return this.activeBuffer === 'A' ? this.sizeB : this.sizeA;
  }

  canPrefetch(): boolean {
    return this.getInactiveSize() < this.maxSize;
  }

  addToInactive(chunk: ArrayBuffer) {
    if (this.activeBuffer === 'A') {
      this.bufferB.push(chunk);
      this.sizeB += chunk.byteLength;
    } else {
      this.bufferA.push(chunk);
      this.sizeA += chunk.byteLength;
    }
  }

  takeFromActive(count: number): ArrayBuffer[] {
    const chunks: ArrayBuffer[] = [];
    const activeChunks = this.activeBuffer === 'A' ? this.bufferA : this.bufferB;

    for (let i = 0; i < count && activeChunks.length > 0; i++) {
      const chunk = activeChunks.shift()!;
      if (this.activeBuffer === 'A') {
        this.sizeA -= chunk.byteLength;
      } else {
        this.sizeB -= chunk.byteLength;
      }
      chunks.push(chunk);
    }

    return chunks;
  }

  swap(): boolean {
    const activeSize = this.getActiveSize();
    const inactiveSize = this.getInactiveSize();

    if (activeSize === 0 && inactiveSize > 0) {
      this.activeBuffer = this.activeBuffer === 'A' ? 'B' : 'A';
      return true;
    }
    return false;
  }

  isEmpty(): boolean {
    return this.sizeA === 0 && this.sizeB === 0;
  }

  clear() {
    this.bufferA = [];
    this.bufferB = [];
    this.sizeA = 0;
    this.sizeB = 0;
    this.activeBuffer = 'A';
  }
}

interface WorkerState {
  files: File[];
  manifest: any;
  mode: 'single' | 'zip';
  currentFileOffset: number;
  zipStream: ReadableStream<Uint8Array> | null;
  zipReader: ReadableStreamDefaultReader<Uint8Array> | null;
  chunkSequence: number;
  totalBytesSent: number;
  startTime: number;
  isInitialized: boolean;
  isCompleted: boolean;
  // ğŸ” ì•”í˜¸í™” í‚¤ ì¶”ê°€
  encryptionKey: CryptoKey | null;
}

const state: WorkerState = {
  files: [],
  manifest: null,
  mode: 'single',
  currentFileOffset: 0,
  zipStream: null,
  zipReader: null,
  chunkSequence: 0,
  totalBytesSent: 0,
  startTime: 0,
  isInitialized: false,
  isCompleted: false,
  encryptionKey: null,
};

const adaptiveConfig: AdaptiveConfig = {
  chunkSize: CHUNK_SIZE_MAX,
  prefetchBatch: PREFETCH_BATCH,
  enableAdaptive: true
};

const chunkPool = new ChunkPool(CHUNK_SIZE_MAX, POOL_SIZE);
const doubleBuffer = new DoubleBuffer(BUFFER_SIZE);
let isTransferActive = false;
let prefetchPromise: Promise<void> | null = null;

// ë°±í”„ë ˆì…” ìƒíƒœ ë³€ìˆ˜
let isZipPaused = false;
let resolveZipResume: (() => void) | null = null;
let currentZipQueueSize = 0;

self.onmessage = (e: MessageEvent) => {
  const { type, payload } = e.data;

  switch (type) {
    case 'init':
      initWorker(payload);
      break;
    case 'process-batch':
      processBatch(payload.count);
      break;
    case 'reset':
      resetWorker();
      break;
    case 'update-config':
      updateAdaptiveConfig(payload);
      break;
    // ğŸš€ [ì‹ ê·œ] NACK ì²˜ë¦¬
    case 'resend-request':
      handleResendRequest(payload.offset);
      break;
  }
};

function updateAdaptiveConfig(config: Partial<AdaptiveConfig>) {
  if (config.chunkSize !== undefined) {
    adaptiveConfig.chunkSize = Math.max(CHUNK_SIZE_MIN, Math.min(CHUNK_SIZE_MAX, config.chunkSize));
    CHUNK_SIZE = adaptiveConfig.chunkSize;
  }
  if (config.prefetchBatch !== undefined) {
    adaptiveConfig.prefetchBatch = Math.max(4, Math.min(32, config.prefetchBatch));
  }
  if (config.enableAdaptive !== undefined) {
    adaptiveConfig.enableAdaptive = config.enableAdaptive;
  }
}

async function initWorker(payload: { files: File[]; manifest: any; encryptionKeyStr?: string }) {
  resetWorker();
  
  state.files = payload.files;
  state.manifest = payload.manifest;
  state.currentFileOffset = 0;
  state.totalBytesSent = 0;
  state.chunkSequence = 0;
  
  state.startTime = 0;
  state.isInitialized = true;
  state.isCompleted = false;

  isTransferActive = true;
  prefetchPromise = null;
  zipBuffer = null;
  
  const fileCount = state.files.length;
  console.log('[Worker] Initializing for', fileCount, 'files');

  // ğŸ” ì•”í˜¸í™” í‚¤ ë¡œë“œ
  if (payload.encryptionKeyStr) {
    try {
      state.encryptionKey = await WorkerEncryptionService.importKey(payload.encryptionKeyStr);
      console.log('[Worker] ğŸ” Encryption Enabled (AES-GCM)');
    } catch (e) {
      console.error('[Worker] Failed to import encryption key:', e);
    }
  }

  if (fileCount === 1) {
    state.mode = 'single';
    // Single ëª¨ë“œì—ì„œëŠ” currentFileOffsetì´ ì´ë¯¸ ì„¤ì •ë˜ì—ˆìœ¼ë¯€ë¡œ createSingleFileChunkì—ì„œ ë°˜ì˜ë¨
  } else {
    state.mode = 'zip';
    try {
      await initZipStream();
      
      await prefetchBatch();
    } catch (error: any) {
      console.error('[Worker] ZIP init failed:', error);
      self.postMessage({ type: 'error', payload: { message: error.message } });
      return;
    }
  }

  triggerPrefetch();
  self.postMessage({ type: 'init-complete' });
}

// ZIP ì†ŒìŠ¤ ì½ê¸° ì§„í–‰ë¥ 
let zipSourceBytesRead = 0;

/**
 * ğŸš€ [Core] fflate ê¸°ë°˜ ì‹¤ì œ ZIP ìŠ¤íŠ¸ë¦¬ë°
 */
async function initZipStream() {
  zipSourceBytesRead = 0;
  currentZipQueueSize = 0;
  isZipPaused = false;
  resolveZipResume = null;

  const zipDataQueue: Uint8Array[] = [];
  let resolveDataAvailable: (() => void) | null = null;
  let zipFinalized = false;
  let hasError = false;

  // í—¬í¼: ì••ì¶• ë°ì´í„°ë¥¼ íì— ë„£ê³  ì•Œë¦¼
  const pushToQueue = (data: Uint8Array) => {
    if (data.length > 0) {
      zipDataQueue.push(data);
      currentZipQueueSize += data.length;
      if (resolveDataAvailable) {
        resolveDataAvailable();
        resolveDataAvailable = null;
      }
    }
  };

  // fflate Zip ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  const zip = new Zip((err, data, final) => {
    if (err) {
      console.error('[Worker] ZIP error:', err);
      hasError = true;
      if (resolveDataAvailable) {
        resolveDataAvailable();
        resolveDataAvailable = null;
      }
      return;
    }
    
    if (data && data.length > 0) {
      pushToQueue(data);
    }
    
    if (final) {
      console.log('[Worker] ZIP stream finalized (fflate)');
      zipFinalized = true;
      if (resolveDataAvailable) {
        resolveDataAvailable();
        resolveDataAvailable = null;
      }
    }
  });

  // íŒŒì¼ ì²˜ë¦¬ ë£¨í”„ (fflate ì‚¬ìš© + ìŠ¤ë§ˆíŠ¸ ì••ì¶•)
  const processFilesAsync = async () => {
    try {
      for (let i = 0; i < state.files.length; i++) {
        if (!isTransferActive) break;
        
        const file = state.files[i];
        let filePath = file.name;
        if (state.manifest && state.manifest.files && state.manifest.files[i]) {
          filePath = state.manifest.files[i].path;
        }
        
        // ğŸš€ [ìŠ¤ë§ˆíŠ¸ ì••ì¶•] íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ê²°ì •
        // ZipPassThrough: ë¹„ì••ì¶• (Store) - ë¯¸ë””ì–´ íŒŒì¼ìš©
        // AsyncZipDeflate: ì••ì¶• (Deflate) - í…ìŠ¤íŠ¸/ì½”ë“œìš© (fflate ì§€ì› í•„ìš”, ì—†ìœ¼ë©´ PassThrough)
        const compressible = isCompressibleFile(filePath);
        
        // ì°¸ê³ : AsyncZipDeflateê°€ import ë˜ì§€ ì•ŠëŠ” í™˜ê²½ì´ë¼ë©´ ZipPassThrough(level 0) ì‚¬ìš©
        // ì—¬ê¸°ì„œëŠ” êµ¬ì¡°ì ìœ¼ë¡œ ë¶„ê¸° ì²˜ë¦¬í•¨
        let fileStream: any;
        
        if (compressible) {
             // í…ìŠ¤íŠ¸ ë“±ì€ ì••ì¶• ì‹œë„ (level 6)
             // ë§Œì•½ AsyncZipDeflateë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤ë©´ ZipPassThrough ì‚¬ìš©
             try {
                 // @ts-ignore
                 fileStream = new AsyncZipDeflate(filePath, { level: 6 });
             } catch (e) {
                 fileStream = new ZipPassThrough(filePath); // Fallback
             }
        } else {
             // ë¯¸ë””ì–´ íŒŒì¼ì€ ì••ì¶• ì—†ì´ ì €ì¥ (ì†ë„ ìµœì í™”)
             fileStream = new ZipPassThrough(filePath);
        }

        zip.add(fileStream);
        
        const reader = file.stream().getReader();
        try {
          while (true) {
            // Backpressure ì²´í¬
            if (currentZipQueueSize > ZIP_QUEUE_HIGH_WATER_MARK) {
              isZipPaused = true;
              await new Promise<void>(resolve => { resolveZipResume = resolve; });
              isZipPaused = false;
            }

            const { done, value } = await reader.read();
            if (done) {
              fileStream.push(new Uint8Array(0), true); // íŒŒì¼ ì¢…ë£Œ
              break;
            }
            
            zipSourceBytesRead += value.length;
            fileStream.push(value, false);
          }
        } finally {
          reader.releaseLock();
        }
      }
      
      // ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ í›„ ZIP ì¢…ë£Œ
      if (isTransferActive) {
        zip.end();
      }
    } catch (e) {
      console.error('[Worker] Fatal ZIP error:', e);
      hasError = true;
      zip.terminate();
    }
  };
  
  // ReadableStream ìƒì„± (Consumerìš©)
  state.zipStream = new ReadableStream({
    async pull(controller) {
      const consumeAndCheckResume = (chunk: Uint8Array) => {
        currentZipQueueSize -= chunk.length;
        controller.enqueue(chunk);
        
        if (isZipPaused && currentZipQueueSize < ZIP_QUEUE_LOW_WATER_MARK) {
          if (resolveZipResume) {
            resolveZipResume();
            resolveZipResume = null;
          }
        }
      };

      if (zipDataQueue.length > 0) {
        consumeAndCheckResume(zipDataQueue.shift()!);
        return;
      }
      if (zipFinalized) {
        controller.close();
        return;
      }
      if (hasError) {
        controller.error(new Error('ZIP failed'));
        return;
      }
      
      await new Promise<void>((resolve) => {
        resolveDataAvailable = resolve;
      });
      
      if (zipDataQueue.length > 0) {
        consumeAndCheckResume(zipDataQueue.shift()!);
      }
      else if (zipFinalized) controller.close();
      else if (hasError) controller.error(new Error('ZIP failed'));
    }
  });
  
  state.zipReader = state.zipStream.getReader();
  processFilesAsync();
  
  // ì´ˆê¸° ë°ì´í„° ëŒ€ê¸° (Fast Start)
  const waitStart = Date.now();
  while (zipDataQueue.length === 0 && !zipFinalized && !hasError && (Date.now() - waitStart) < 2000) {
    await new Promise(resolve => setTimeout(resolve, 1));
  }
}

function resetWorker() {
  isTransferActive = false;
  if (state.zipReader) {
    state.zipReader.cancel();
    state.zipReader = null;
  }

  if (resolveZipResume) {
    resolveZipResume();
    resolveZipResume = null;
  }
  isZipPaused = false;
  currentZipQueueSize = 0;

  state.isInitialized = false;
  state.isCompleted = false;
  state.files = [];
  
  chunkPool.clear();
  doubleBuffer.clear();
  zipBuffer = null;
  historyBuffer.clear();
  priorityQueue.length = 0;
}

function triggerPrefetch() {
  if (prefetchPromise || state.isCompleted || !isTransferActive) return;
  if (!doubleBuffer.canPrefetch()) return;

  prefetchPromise = prefetchBatch().finally(() => {
    prefetchPromise = null;
    if (isTransferActive && !state.isCompleted && doubleBuffer.canPrefetch()) {
      triggerPrefetch();
    }
  });
}

async function prefetchBatch(): Promise<void> {
  const batchSize = adaptiveConfig.enableAdaptive ? adaptiveConfig.prefetchBatch : PREFETCH_BATCH;
  for (let i = 0; i < batchSize && isTransferActive && !state.isCompleted; i++) {
    if (!doubleBuffer.canPrefetch()) break;
    const chunk = await createNextChunk();
    if (chunk) doubleBuffer.addToInactive(chunk);
    else break;
  }
}

async function createNextChunk(): Promise<ArrayBuffer | null> {
  if (state.mode === 'single') return createSingleFileChunk();
  return createZipChunk();
}

async function createSingleFileChunk(): Promise<ArrayBuffer | null> {
  if (state.files.length === 0) return null;
  const file = state.files[0];
  
  if (state.currentFileOffset >= file.size) {
    state.isCompleted = true;
    return null;
  }

  const currentChunkSize = adaptiveConfig.enableAdaptive ? adaptiveConfig.chunkSize : CHUNK_SIZE_MAX;
  const start = state.currentFileOffset;
  const end = Math.min(start + currentChunkSize, file.size);

  state.currentFileOffset = end;

  try {
    // íŒŒì¼ ì½ê¸° ì‹œì‘
    const blob = file.slice(start, end);
    const buffer = await blob.arrayBuffer();
    
    if (buffer.byteLength === 0) return null;
    
    return await createPacket(new Uint8Array(buffer), buffer.byteLength);
  } catch (e) {
    console.error('[Worker] Single chunk error:', e);
    return null;
  }
}

let zipBuffer: Uint8Array | null = null;

async function createZipChunk(): Promise<ArrayBuffer | null> {
  if (!state.zipReader) {
    state.isCompleted = true;
    return null;
  }

  const targetChunkSize = adaptiveConfig.enableAdaptive ? adaptiveConfig.chunkSize : CHUNK_SIZE_MAX;

  if (zipBuffer && zipBuffer.length >= targetChunkSize) {
    const chunkData = zipBuffer.slice(0, targetChunkSize);
    const remaining = zipBuffer.slice(targetChunkSize);
    zipBuffer = remaining.length > 0 ? remaining : null;
    const packet = await createPacket(chunkData, chunkData.length);
    // ğŸš¨ ë¹ˆ íŒ¨í‚· í•„í„°ë§
    return packet.byteLength > 0 ? packet : null;
  }

  while (true) {
    try {
      const { done, value } = await state.zipReader.read();

      if (done) {
        if (zipBuffer && zipBuffer.length > 0) {
          const chunkData = zipBuffer;
          zipBuffer = null;
          const packet = await createPacket(chunkData, chunkData.length);
          // ğŸš¨ ë¹ˆ íŒ¨í‚· í•„í„°ë§
          if (packet.byteLength > 0) {
            return packet;
          }
        }
        state.isCompleted = true;
        return null;
      }

      if (value && value.length > 0) {
        if (zipBuffer) {
          const newBuffer = new Uint8Array(zipBuffer.length + value.length);
          newBuffer.set(zipBuffer);
          newBuffer.set(value, zipBuffer.length);
          zipBuffer = newBuffer;
        } else {
          zipBuffer = value;
        }

        if (zipBuffer.length >= targetChunkSize) {
          const chunkData = zipBuffer.slice(0, targetChunkSize);
          const remaining = zipBuffer.slice(targetChunkSize);
          zipBuffer = remaining.length > 0 ? remaining : null;
          const packet = await createPacket(chunkData, chunkData.length);
          // ğŸš¨ ë¹ˆ íŒ¨í‚· í•„í„°ë§
          return packet.byteLength > 0 ? packet : null;
        }
      }
    } catch (e) {
      console.error('[Worker] ZIP chunk error:', e);
      state.isCompleted = true;
      return null;
    }
  }
}

async function createPacket(data: Uint8Array, dataSize: number): Promise<ArrayBuffer> {
  // ğŸš¨ ZIP ëª¨ë“œì—ì„œëŠ” í¬ê¸° ì œí•œ ì²´í¬ ì•ˆ í•¨ (ì••ì¶• í›„ í¬ê¸°ê°€ ë‹¤ë¦„)
  if (state.mode === 'single' && state.manifest && state.manifest.totalSize > 0) {
    if (state.totalBytesSent >= state.manifest.totalSize) {
      console.warn('[Worker] Already sent totalSize, stopping:', state.totalBytesSent, '>=', state.manifest.totalSize);
      return new ArrayBuffer(0);
    }
    if (state.totalBytesSent + dataSize > state.manifest.totalSize) {
      const remaining = state.manifest.totalSize - state.totalBytesSent;
      if (remaining <= 0) return new ArrayBuffer(0);
      console.warn('[Worker] Truncating last chunk:', dataSize, '->', remaining);
      data = data.subarray(0, remaining);
      dataSize = remaining;
    }
  }

  // ğŸ” [ë³´ì•ˆ] ì•”í˜¸í™” í™œì„±í™”
  // ê¸°ì¡´: if (false && state.encryptionKey)
  if (state.encryptionKey) {
    try {
      // ì²­í¬ ì¸ë±ìŠ¤ë¥¼ IV ì¹´ìš´í„°ë¡œ ì‚¬ìš© (Deterministic IV)
      const encryptedData = await WorkerEncryptionService.encryptChunk(
        state.encryptionKey,
        data.buffer.slice(data.byteOffset, data.byteOffset + dataSize) as ArrayBuffer,
        state.chunkSequence
      );
      
      // ì•”í˜¸í™”ëœ ë°ì´í„°ë¡œ êµì²´ (AES-GCM Tag 16bytes ì¶”ê°€ë¨)
      data = new Uint8Array(encryptedData);
      dataSize = encryptedData.byteLength;
    } catch (e) {
      console.error('[Worker] Encryption failed:', e);
      throw e; // ì¹˜ëª…ì  ì˜¤ë¥˜: ì•”í˜¸í™” ì‹¤íŒ¨ ì‹œ ì „ì†¡ ì¤‘ë‹¨
    }
  }

  const packet = chunkPool.acquire();
  
  // íŒ¨í‚· í¬ê¸°ê°€ í’€ ì‚¬ì´ì¦ˆë³´ë‹¤ ì»¤ì¡Œì„ ê²½ìš° (ì•”í˜¸í™” íƒœê·¸ ë•Œë¬¸) ì˜ˆì™¸ ì²˜ë¦¬ í•„ìš”í•˜ì§€ë§Œ,
  // í˜„ì¬ í’€ ì‚¬ì´ì¦ˆ(CHUNK_SIZE + 18)ì— ì—¬ìœ ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ í• ë‹¹í•´ì•¼ í•¨.
  // ê°„ë‹¨íˆ ì²˜ë¦¬:
  const requiredSize = 18 + dataSize;
  let targetPacket = packet;
  if (packet.byteLength < requiredSize) {
      targetPacket = new Uint8Array(requiredSize); // í’€ ëŒ€ì‹  ìƒˆ ë²„í¼ ì‚¬ìš© (ë“œë¬¸ ì¼€ì´ìŠ¤)
  }

  const view = new DataView(targetPacket.buffer);

  // Header: FileIndex(2) + ChunkIndex(4) + Offset(8) + Length(4)
  view.setUint16(0, 0, true);
  view.setUint32(2, state.chunkSequence++, true);
  view.setBigUint64(6, BigInt(state.totalBytesSent), true);
  view.setUint32(14, dataSize, true); // ì•”í˜¸í™”ëœ í¬ê¸° ê¸°ë¡

  targetPacket.set(data, 18);
  state.totalBytesSent += dataSize; // ì•”í˜¸í™”ëœ í¬ê¸°ë§Œí¼ ì¦ê°€ (ì‹¤ì œ ì „ì†¡ëŸ‰)

  const result = new ArrayBuffer(requiredSize);
  new Uint8Array(result).set(targetPacket.subarray(0, requiredSize));
  
  if (packet === targetPacket) chunkPool.release(packet);

  return result;
}

function processBatch(requestedCount: number) {
  if (!state.isInitialized) return;

  if (state.startTime === 0) state.startTime = Date.now();
  if (doubleBuffer.getActiveSize() === 0) doubleBuffer.swap();

  // ğŸš€ 1. ìš°ì„ ìˆœìœ„ í(ì¬ì „ì†¡) ë¨¼ì € í™•ì¸
  const chunks: ArrayBuffer[] = [];
  
  while (priorityQueue.length > 0 && chunks.length < requestedCount) {
      chunks.push(priorityQueue.shift()!);
  }

  // ğŸš€ 2. ë¶€ì¡±í•˜ë©´ ì¼ë°˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
  const remainingCount = requestedCount - chunks.length;
  if (remainingCount > 0) {
      const newChunks = doubleBuffer.takeFromActive(remainingCount);
      
      // ğŸš€ 3. ìƒˆë¡œ ë³´ë‚¼ ì²­í¬ë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥
      for (const chunk of newChunks) {
          const view = new DataView(chunk);
          // Header: FileId(2) + ChunkSeq(4) + Offset(8)...
          const offset = Number(view.getBigUint64(6, true));
          
          // ChunkPoolì€ ì¬ì‚¬ìš©ë˜ë¯€ë¡œ ë³µì‚¬ë³¸ì„ ì €ì¥í•´ì•¼ í•¨
          // (ì „ì†¡ ì‹œ Transferableë¡œ ì†Œìœ ê¶Œì´ ë„˜ì–´ê°€ë©´ ì›ë³¸ì´ ì‚¬ë¼ì§ˆ ìˆ˜ ìˆìŒ)
          const copy = new Uint8Array(chunk).slice(0);
          historyBuffer.add(offset, copy);
          
          chunks.push(chunk);
      }
  }
  
  const elapsed = (Date.now() - state.startTime) / 1000;
  const speed = elapsed > 0 ? state.totalBytesSent / elapsed : 0;
  let progress = 0;
  const totalSize = state.manifest?.totalSize || 0;
  
  if (state.mode === 'zip') {
    // ZIP ëª¨ë“œëŠ” ì†ŒìŠ¤ ì½ê¸° ê¸°ì¤€ìœ¼ë¡œ ì§„í–‰ë¥  ì¶”ì • (ì••ì¶•ë¥  ë³€ë™ì„± ë³´ì •)
    progress = totalSize > 0 ? Math.min(100, (zipSourceBytesRead / totalSize) * 100) : 0;
  } else {
    progress = totalSize > 0 ? Math.min(100, (state.totalBytesSent / totalSize) * 100) : 0;
  }

  if (chunks.length > 0) {
    self.postMessage({
      type: 'chunk-batch',
      payload: {
        chunks,
        progressData: {
          bytesTransferred: state.mode === 'zip' ? zipSourceBytesRead : state.totalBytesSent,
          totalBytes: totalSize,
          speed,
          progress
        }
      }
    }, chunks);
  }

  if (state.isCompleted && doubleBuffer.isEmpty() && (!zipBuffer || zipBuffer.length === 0)) {
    self.postMessage({ type: 'complete' });
    return;
  }

  triggerPrefetch();

  if (chunks.length === 0 && !state.isCompleted) {
    createAndSendImmediate(requestedCount);
  }
}

// ğŸš€ NACK ìš”ì²­ ì²˜ë¦¬
function handleResendRequest(missingOffset: number) {
    console.log('[Worker] ğŸš¨ Resend requested for offset:', missingOffset);
    
    // 1. íˆìŠ¤í† ë¦¬ ë²„í¼ì—ì„œ ì°¾ê¸° (Offsetì€ í—¤ë” ì œì™¸ ìˆœìˆ˜ ë°ì´í„° ì‹œì‘ì )
    // ì£¼ì˜: íŒ¨í‚· í—¤ë”ì˜ offset í•„ë“œì™€ ë§¤ì¹­ë˜ì–´ì•¼ í•¨.
    // ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ HistoryBufferê°€ ì™„ì„±ëœ íŒ¨í‚·(í—¤ë” í¬í•¨)ì„ ì €ì¥í•œë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜,
    // ì•„ë‹ˆë©´ ì²­í¬ ì‹œí€€ìŠ¤ë¡œ ì°¾ëŠ” ê²ƒì´ ë” ì •í™•í•  ìˆ˜ ìˆìŒ.
    // í˜„ì¬ êµ¬ì¡°ìƒ 'totalBytesSent'ê°€ Offset ì—­í• ì„ í•˜ë¯€ë¡œ, ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì°¾ìŒ.
    
    // * ê°œì„ : HistoryBuffer í‚¤ë¥¼ 'Offset'ìœ¼ë¡œ ì‚¬ìš©.
    const packet = historyBuffer.get(missingOffset);
    
    if (packet) {
        console.log('[Worker] âœ… Found in history, queuing for resend.');
        // ìš°ì„ ìˆœìœ„ íì— ì¶”ê°€ (ë‹¤ìŒ ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ìµœìš°ì„  ì „ì†¡)
        // ArrayBuffer ë³µì‚¬ë³¸ì„ ë§Œë“¤ì–´ì•¼ ì•ˆì „í•¨ (Transferableë¡œ ë‚ ì•„ê°ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        const packetCopy = new Uint8Array(packet).buffer;
        priorityQueue.push(packetCopy);
    } else {
        console.warn('[Worker] âš ï¸ Packet expired from history buffer. Cannot resend offset:', missingOffset);
        // ì‹¬ê°í•œ ê²½ìš°: ì—¬ê¸°ì„œ íŒŒì¼ ì½ê¸°ë¥¼ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜, ì—ëŸ¬ ì²˜ë¦¬
    }
}

async function createAndSendImmediate(count: number) {
  if (!state.isInitialized) return;

  const chunks: ArrayBuffer[] = [];
  for (let i = 0; i < count && !state.isCompleted; i++) {
    const chunk = await createNextChunk();
    if (chunk) chunks.push(chunk);
    else break;
  }

  if (chunks.length > 0) {
    const totalSize = state.manifest?.totalSize || 0;
    let progress = 0;
    if (state.mode === 'zip') progress = totalSize > 0 ? Math.min(100, (zipSourceBytesRead / totalSize) * 100) : 0;
    else progress = totalSize > 0 ? Math.min(100, (state.totalBytesSent / totalSize) * 100) : 0;

    self.postMessage({
      type: 'chunk-batch',
      payload: {
        chunks,
        progressData: {
          bytesTransferred: state.mode === 'zip' ? zipSourceBytesRead : state.totalBytesSent,
          totalBytes: totalSize,
          speed: 0, 
          progress
        }
      }
    }, chunks);
  }

  if (state.isCompleted && doubleBuffer.isEmpty() && (!zipBuffer || zipBuffer.length === 0)) {
    self.postMessage({ type: 'complete' });
  }
}


self.postMessage({ type: 'ready' });

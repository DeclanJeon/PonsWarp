/// <reference lib="webworker" />
declare const self: DedicatedWorkerGlobalScope;

// ğŸš€ [Pull-Based] ìƒíƒœ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤
interface WorkerState {
  files: File[];
  manifest: any;
  currentFileIndex: number;
  currentFileOffset: number;
  chunkSequence: number;
  totalBytesSent: number;
  startTime: number;
  chunkSize: number;
  isInitialized: boolean;
  isCompleted: boolean;
}

// ğŸš€ [Dynamic Chunk Sizing] ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ì¶”ì 
interface NetworkMetrics {
  rtt: number; // Round Trip Time
  throughput: number; // bytes per second
  bufferDrainRate: number; // ë²„í¼ ë¹„ì›Œì§€ëŠ” ì†ë„
  lastAdjustmentTime: number;
  consecutiveSuccesses: number;
  consecutiveFailures: number;
}

// ğŸš€ [State Machine] ìƒíƒœ ì •ì˜
enum WorkerStateType {
  IDLE = 'IDLE',
  INITIALIZING = 'INITIALIZING',
  READY = 'READY',
  PROCESSING_BATCH = 'PROCESSING_BATCH',
  PAUSED = 'PAUSED',
  ERROR = 'ERROR',
  COMPLETED = 'COMPLETED'
}

// ğŸš€ [State Machine] ìƒíƒœ ì „ì´ ê·œì¹™
const stateTransitions: Record<WorkerStateType, WorkerStateType[]> = {
  [WorkerStateType.IDLE]: [WorkerStateType.INITIALIZING],
  [WorkerStateType.INITIALIZING]: [WorkerStateType.READY, WorkerStateType.ERROR],
  [WorkerStateType.READY]: [WorkerStateType.PROCESSING_BATCH, WorkerStateType.PAUSED, WorkerStateType.ERROR],
  [WorkerStateType.PROCESSING_BATCH]: [WorkerStateType.READY, WorkerStateType.PAUSED, WorkerStateType.ERROR, WorkerStateType.COMPLETED],
  [WorkerStateType.PAUSED]: [WorkerStateType.READY, WorkerStateType.ERROR],
  [WorkerStateType.ERROR]: [WorkerStateType.IDLE, WorkerStateType.INITIALIZING],
  [WorkerStateType.COMPLETED]: [WorkerStateType.IDLE, WorkerStateType.INITIALIZING]
};

const state: WorkerState = {
  files: [],
  manifest: null,
  currentFileIndex: 0,
  currentFileOffset: 0,
  chunkSequence: 0,
  totalBytesSent: 0,
  startTime: 0,
  chunkSize: 32 * 1024, // 32KB (ì‹œì‘ í¬ê¸°)
  isInitialized: false,
  isCompleted: false
};

// ğŸš€ [Dynamic Chunk Sizing] ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
const networkMetrics: NetworkMetrics = {
  rtt: 100, // 100ms ì´ˆê¸°ê°’
  throughput: 1024 * 1024, // 1MB/s ì´ˆê¸°ê°’
  bufferDrainRate: 1024 * 1024, // 1MB/s ì´ˆê¸°ê°’
  lastAdjustmentTime: 0,
  consecutiveSuccesses: 0,
  consecutiveFailures: 0
};

let currentState: WorkerStateType = WorkerStateType.IDLE;

self.onmessage = async (e: MessageEvent) => {
  const { type, payload } = e.data;

  console.log('[DEBUG Worker] Message received:', {
    type,
    payload: payload ? 'has payload' : 'no payload',
    currentState,
    currentChunkSize: state.chunkSize
  });

  switch (type) {
    case 'init':
      // ğŸš€ [State Machine] ì´ˆê¸°í™”
      if (!transitionState(currentState, WorkerStateType.INITIALIZING)) {
        console.log('[DEBUG Worker] Invalid transition from', currentState, 'to INITIALIZING');
        return;
      }
      
      try {
        state.files = payload.files;
        state.manifest = payload.manifest;
        state.currentFileIndex = 0;
        state.currentFileOffset = 0;
        state.chunkSequence = 0;
        state.totalBytesSent = 0;
        state.startTime = 0;
        state.isInitialized = true;
        state.isCompleted = false;
        
        // ğŸš€ [Dynamic Chunk Sizing] ì´ˆê¸°í™”
        networkMetrics.lastAdjustmentTime = Date.now();
        networkMetrics.consecutiveSuccesses = 0;
        networkMetrics.consecutiveFailures = 0;
        
        transitionState(currentState, WorkerStateType.READY);
        
        console.log('[DEBUG Worker] Initialized:', {
          fileCount: state.files.length,
          totalSize: state.manifest.totalSize,
          chunkSize: state.chunkSize,
          state: currentState
        });
      } catch (error) {
        console.error('[DEBUG Worker] Initialization failed:', error);
        transitionState(currentState, WorkerStateType.ERROR);
      }
      break;

    case 'process-batch': // ğŸš€ [Pull-Based] ë°°ì¹˜ ì²˜ë¦¬ ìš”ì²­
      if (!transitionState(currentState, WorkerStateType.PROCESSING_BATCH)) {
        console.log('[DEBUG Worker] Cannot process batch, invalid state:', currentState);
        return;
      }
      
      try {
        console.log('[DEBUG Worker] Processing batch request:', {
          count: payload.count,
          currentChunkSize: state.chunkSize
        });
        await processBatch(payload.count);
        transitionState(WorkerStateType.PROCESSING_BATCH, WorkerStateType.READY);
      } catch (error) {
        console.error('[DEBUG Worker] Batch processing failed:', error);
        transitionState(WorkerStateType.PROCESSING_BATCH, WorkerStateType.ERROR);
      }
      break;

    case 'network-feedback': // ğŸš€ [Dynamic Chunk Sizing] ë„¤íŠ¸ì›Œí¬ í”¼ë“œë°±
      if (payload && (currentState === WorkerStateType.READY || currentState === WorkerStateType.PROCESSING_BATCH)) {
        updateNetworkMetrics(payload);
        adjustChunkSize();
      } else {
        console.log('[DEBUG Worker] Ignoring network feedback, invalid state:', currentState);
      }
      break;

    case 'reset': // ğŸš€ [State Machine] ìƒíƒœ ë¦¬ì…‹
      if (!transitionState(currentState, WorkerStateType.IDLE)) {
        console.log('[DEBUG Worker] Cannot reset, invalid state:', currentState);
        return;
      }
      
      // ìƒíƒœ ì´ˆê¸°í™”
      state.files = [];
      state.manifest = null;
      state.currentFileIndex = 0;
      state.currentFileOffset = 0;
      state.chunkSequence = 0;
      state.totalBytesSent = 0;
      state.startTime = 0;
      state.isInitialized = false;
      state.isCompleted = false;
      state.chunkSize = 32 * 1024; // ê¸°ë³¸ê°’ìœ¼ë¡œ ë¦¬ì…‹
      
      console.log('[DEBUG Worker] State reset to IDLE');
      break;

    case 'start':
      // ğŸš€ [Pull-Based] ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ (process-batchë¡œ ëŒ€ì²´)
      console.log('[DEBUG Worker] Legacy start command ignored, use process-batch instead');
      break;

    case 'resume': // ğŸš€ [Legacy] í•˜ìœ„ í˜¸í™˜ì„±
      console.log('[DEBUG Worker] Legacy resume command ignored');
      break;

    case 'pause': // ğŸš€ [Legacy] í•˜ìœ„ í˜¸í™˜ì„±
      console.log('[DEBUG Worker] Legacy pause command ignored');
      break;
  }
};

// ğŸš€ [State Machine] ìƒíƒœ ì „ì´ í•¨ìˆ˜
function transitionState(from: WorkerStateType, to: WorkerStateType): boolean {
  if (!stateTransitions[from] || !stateTransitions[from].includes(to)) {
    console.log('[DEBUG Worker] âŒ Invalid state transition:', {
      from,
      to,
      allowedTransitions: stateTransitions[from]
    });
    return false;
  }
  
  console.log('[DEBUG Worker] âœ… State transition:', {
    from,
    to,
    timestamp: Date.now()
  });
  
  currentState = to;
  return true;
}

// ğŸš€ [Pull-Based] ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ - ë©”ì¸ ìŠ¤ë ˆë“œì˜ ìš”ì²­ì— ë”°ë¼ ì²­í¬ ìƒì„±
async function processBatch(requestedCount: number) {
  if (currentState !== WorkerStateType.PROCESSING_BATCH) {
    console.log('[DEBUG Worker] Cannot process batch, invalid state:', {
      currentState,
      isCompleted: state.isCompleted
    });
    return;
  }

  // ğŸš€ [ì†ë„ ê³„ì‚°] ì²« ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì‹œì‘ ì‹œê°„ ê¸°ë¡
  if (state.startTime === 0) {
    state.startTime = Date.now();
    console.log('[DEBUG Worker] Transfer started, recording start time');
  }

  const batchStartTime = performance.now();
  const chunks: ArrayBuffer[] = [];
  let actualProcessed = 0;

  console.log('[DEBUG Worker] Starting batch processing:', {
    requestedCount,
    currentFileIndex: state.currentFileIndex,
    currentOffset: state.currentFileOffset
  });

  // ìš”ì²­ëœ ìˆ˜ë§Œí¼ ì²­í¬ ìƒì„±
  for (let i = 0; i < requestedCount; i++) {
    if (state.currentFileIndex >= state.files.length) {
      console.log('[DEBUG Worker] All files processed');
      state.isCompleted = true;
      currentState = WorkerStateType.COMPLETED;
      break;
    }

    const file = state.files[state.currentFileIndex];
    const start = state.currentFileOffset;
    
    // íŒŒì¼ ë ë„ë‹¬ ì‹œ ë‹¤ìŒ íŒŒì¼ë¡œ
    if (start >= file.size) {
      console.log('[DEBUG Worker] File completed, moving to next file:', {
        fileIndex: state.currentFileIndex,
        fileName: file.name,
        fileSize: file.size
      });
      
      state.currentFileIndex++;
      state.currentFileOffset = 0;
      
      // ë‹¤ìŒ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì™„ë£Œ
      if (state.currentFileIndex >= state.files.length) {
        console.log('[DEBUG Worker] All files completed');
        state.isCompleted = true;
        currentState = WorkerStateType.COMPLETED;
        break;
      }
      
      // ë‹¤ìŒ íŒŒì¼ì˜ ì²­í¬ ì²˜ë¦¬ ê³„ì†
      i--; // í˜„ì¬ ì¸ë±ìŠ¤ ë‹¤ì‹œ ì‹œë„
      continue;
    }

    // ğŸš€ [Zero-Copy ì§€í–¥] ì²­í¬ ìƒì„±
    const chunk = await createChunk(state.currentFileIndex, start);
    if (chunk) {
      chunks.push(chunk);
      actualProcessed++;
      
      // ì˜¤í”„ì…‹ ì—…ë°ì´íŠ¸
      state.currentFileOffset += chunk.byteLength - 18; // í—¤ë” ì œì™¸
      
      // ğŸš€ [Dynamic Chunk Sizing] ë„¤íŠ¸ì›Œí¬ ì„±ê³µ ì¹´ìš´íŠ¸
      networkMetrics.consecutiveSuccesses++;
      networkMetrics.consecutiveFailures = 0;
    } else {
      console.error('[DEBUG Worker] Failed to create chunk');
      networkMetrics.consecutiveFailures++;
      networkMetrics.consecutiveSuccesses = 0;
      break;
    }
  }

  // ì§„í–‰ë¥  ê³„ì‚°
  const elapsed = state.startTime > 0 ? (Date.now() - state.startTime) / 1000 : 0;
  const speed = elapsed > 0 ? state.totalBytesSent / elapsed : 0;
  const progressData = {
    bytesTransferred: state.totalBytesSent,
    totalBytes: state.manifest.totalSize,
    speed,
    progress: state.manifest.totalSize > 0 ? (state.totalBytesSent / state.manifest.totalSize) * 100 : 0
  };

  const batchEndTime = performance.now();

  console.log('[DEBUG Worker] Batch processing completed:', {
    requestedCount,
    actualProcessed,
    batchTimeMs: (batchEndTime - batchStartTime).toFixed(2),
    totalBytesSent: state.totalBytesSent,
    progress: progressData.progress.toFixed(2) + '%'
  });

  // ğŸš€ [Pull-Based] ë°°ì¹˜ë¥¼ ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ì „ì†¡
  if (chunks.length > 0) {
    self.postMessage({
      type: 'chunk-batch',
      payload: {
        chunks,
        progressData
      }
    }, chunks); // Transferable ê°ì²´ë¡œ ì „ì†¡
  }

  // ì „ì†¡ ì™„ë£Œ ì²˜ë¦¬
  if (state.isCompleted) {
    console.log('[DEBUG Worker] Transfer completed, sending complete message');
    self.postMessage({ type: 'complete' });
    transitionState(WorkerStateType.PROCESSING_BATCH, WorkerStateType.COMPLETED);
  }
}

// ğŸš€ [Zero-Copy] ì²­í¬ ìƒì„± í•¨ìˆ˜ - ë©”ëª¨ë¦¬ ë³µì‚¬ ìµœì†Œí™”
async function createChunk(fileIndex: number, offset: number): Promise<ArrayBuffer | null> {
  let buffer: ArrayBuffer | null = null;
  let packet: Uint8Array | null = null;
  let sourceData: Uint8Array | null = null;
  
  try {
    const file = state.files[fileIndex];
    const end = Math.min(offset + state.chunkSize, file.size);
    const blob = file.slice(offset, end);
    
    // ğŸš¨ [ì§„ë‹¨] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
    const beforeRead = performance.now();
    buffer = await blob.arrayBuffer(); // íŒŒì¼ ì½ê¸°
    const afterRead = performance.now();
    
    console.log('[DEBUG Worker] Chunk read:', {
      fileIndex,
      offset,
      end,
      chunkSize: buffer.byteLength,
      readTimeMs: (afterRead - beforeRead).toFixed(2)
    });

    // ğŸš€ [Zero-Copy ê°œì„ ] íŒ¨í‚· ìƒì„± - ë‹¨ì¼ ë²„í¼ í• ë‹¹ìœ¼ë¡œ ë³µì‚¬ íšŸìˆ˜ ê°ì†Œ
    const beforePacket = performance.now();
    
    // 18 bytes header + data - ë‹¨ì¼ ë²„í¼ í• ë‹¹
    packet = new Uint8Array(18 + buffer.byteLength);
    const view = new DataView(packet.buffer);

    // Header ì‘ì„±
    view.setUint16(0, fileIndex, true);
    view.setUint32(2, state.chunkSequence++, true);
    view.setBigUint64(6, BigInt(offset), true);
    view.setUint32(14, buffer.byteLength, true);

    // ğŸš€ [Zero-Copy] ë°ì´í„° ë³µì‚¬ ìµœì í™” - ë‹¨ì¼ ë³µì‚¬ ì—°ì‚°
    sourceData = new Uint8Array(buffer);
    packet.set(sourceData, 18);
    
    const afterPacket = performance.now();
    
    console.log('[DEBUG Worker] Optimized packet created:', {
      packetSize: packet.byteLength,
      headerSize: 18,
      dataSize: buffer.byteLength,
      creationTimeMs: (afterPacket - beforePacket).toFixed(2),
      chunkSequence: state.chunkSequence - 1,
      copyOperations: 'single-copy-optimized'
    });

    // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
    state.totalBytesSent += buffer.byteLength;

    // ğŸš€ [ë©”ëª¨ë¦¬ ìµœì í™”] ê²°ê³¼ ë°˜í™˜ ì „ ë¶ˆí•„ìš”í•œ ì°¸ì¡° ì •ë¦¬
    const result = packet.buffer.slice(0) as ArrayBuffer; // ëª…ì‹œì  ArrayBuffer ë³€í™˜
    
    // ëª…ì‹œì  ë©”ëª¨ë¦¬ í•´ì œ (GC íŒíŠ¸)
    sourceData = null;
    buffer = null;
    packet = null;
    
    // ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì œì•ˆ (ì£¼ê¸°ì ìœ¼ë¡œ)
    if (state.chunkSequence % 100 === 0) {
      if (globalThis.gc) {
        globalThis.gc();
        console.log('[DEBUG Worker] GC suggested (every 100 chunks)');
      }
    }

    return result;
  } catch (error) {
    console.error('[DEBUG Worker] Error creating chunk:', error);
    
    // ğŸš€ [ë©”ëª¨ë¦¬ ìµœì í™”] ì—ëŸ¬ ë°œìƒ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬
    sourceData = null;
    buffer = null;
    packet = null;
    
    return null;
  }
}

// ğŸš€ [Zero-Copy] ìµœì í™”ëœ ì²­í¬ ìƒì„± í•¨ìˆ˜ - Transferable Objects í™œìš©
async function createChunkOptimized(fileIndex: number, offset: number): Promise<{header: ArrayBuffer, data: ArrayBuffer} | null> {
  let buffer: ArrayBuffer | null = null;
  let headerBuffer: ArrayBuffer | null = null;
  
  try {
    const file = state.files[fileIndex];
    const end = Math.min(offset + state.chunkSize, file.size);
    const blob = file.slice(offset, end);
    
    // ğŸš¨ [ì§„ë‹¨] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
    const beforeRead = performance.now();
    buffer = await blob.arrayBuffer(); // íŒŒì¼ ì½ê¸°
    const afterRead = performance.now();
    
    console.log('[DEBUG Worker] Optimized chunk read:', {
      fileIndex,
      offset,
      end,
      chunkSize: buffer.byteLength,
      readTimeMs: (afterRead - beforeRead).toFixed(2)
    });

    // ğŸš€ [Zero-Copy] í—¤ë”ì™€ ë°ì´í„°ë¥¼ ì™„ì „íˆ ë¶„ë¦¬
    const beforeHeader = performance.now();
    
    // í—¤ë” ìƒì„± (18 bytes) - ë³„ë„ ë²„í¼
    headerBuffer = new ArrayBuffer(18);
    const headerView = new DataView(headerBuffer);
    
    // Header ì‘ì„±
    headerView.setUint16(0, fileIndex, true);
    headerView.setUint32(2, state.chunkSequence++, true);
    headerView.setBigUint64(6, BigInt(offset), true);
    headerView.setUint32(14, buffer.byteLength, true);
    
    const afterHeader = performance.now();
    
    console.log('[DEBUG Worker] Optimized header created:', {
      headerSize: 18,
      dataSize: buffer.byteLength,
      headerTimeMs: (afterHeader - beforeHeader).toFixed(2),
      chunkSequence: state.chunkSequence - 1,
      copyOperations: 'none (zero-copy)'
    });

    // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
    state.totalBytesSent += buffer.byteLength;

    const result = {
      header: headerBuffer,
      data: buffer // ì›ë³¸ ë°ì´í„° ë²„í¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë³µì‚¬ ì—†ìŒ)
    };
    
    // ğŸš€ [ë©”ëª¨ë¦¬ ìµœì í™”] ë¶ˆí•„ìš”í•œ ì°¸ì¡° ì •ë¦¬
    headerBuffer = null;
    buffer = null;
    
    return result;
  } catch (error) {
    console.error('[DEBUG Worker] Error creating optimized chunk:', error);
    
    // ğŸš€ [ë©”ëª¨ë¦¬ ìµœì í™”] ì—ëŸ¬ ë°œìƒ ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬
    headerBuffer = null;
    buffer = null;
    
    return null;
  }
}

// ğŸš€ [ë©”ëª¨ë¦¬ ìµœì í™”] ëª…ì‹œì  ë©”ëª¨ë¦¬ ì •ë¦¬ í•¨ìˆ˜
function forceMemoryCleanup() {
  // ëŒ€ìš©ëŸ‰ ê°ì²´ ì°¸ì¡° ì •ë¦¬
  if (state.files.length > 0) {
    console.log('[DEBUG Worker] Force memory cleanup:', {
      filesCount: state.files.length,
      totalBytesSent: state.totalBytesSent,
      chunkSequence: state.chunkSequence
    });
  }
  
  // ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
  if (globalThis.gc) {
    globalThis.gc();
    console.log('[DEBUG Worker] Forced garbage collection');
  }
}

// ğŸš€ [Dynamic Chunk Sizing] ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
function updateNetworkMetrics(feedback: any) {
  if (feedback.rtt) {
    networkMetrics.rtt = feedback.rtt;
  }
  
  if (feedback.throughput) {
    networkMetrics.throughput = feedback.throughput;
  }
  
  if (feedback.bufferDrainRate) {
    networkMetrics.bufferDrainRate = feedback.bufferDrainRate;
  }
  
  console.log('[DEBUG Worker] Network metrics updated:', {
    rtt: networkMetrics.rtt,
    throughput: networkMetrics.throughput,
    bufferDrainRate: networkMetrics.bufferDrainRate,
    consecutiveSuccesses: networkMetrics.consecutiveSuccesses,
    consecutiveFailures: networkMetrics.consecutiveFailures
  });
}

// ğŸš€ [Dynamic Chunk Sizing] AIMD ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì²­í¬ í¬ê¸° ì¡°ì ˆ
function adjustChunkSize() {
  const now = Date.now();
  const timeSinceLastAdjustment = now - networkMetrics.lastAdjustmentTime;
  
  // ìµœì†Œ ì¡°ì ˆ ê°„ê²© (1ì´ˆ)
  if (timeSinceLastAdjustment < 1000) {
    return;
  }
  
  const oldChunkSize = state.chunkSize;
  const MIN_CHUNK = 16 * 1024;  // 16KB
  const MAX_CHUNK = 256 * 1024; // 256KB
  
  // ğŸš€ [AIMD] Additive Increase / Multiplicative Decrease
  if (networkMetrics.consecutiveFailures > 2) {
    // ì‹¤íŒ¨ê°€ ì—°ì†ë˜ë©´ ì²­í¬ í¬ê¸° ê°ì†Œ (Multiplicative Decrease)
    state.chunkSize = Math.max(MIN_CHUNK, Math.floor(state.chunkSize * 0.75));
    
    console.log('[DEBUG Worker] Chunk size decreased (MD):', {
      oldSize: oldChunkSize,
      newSize: state.chunkSize,
      reason: 'consecutive failures',
      failures: networkMetrics.consecutiveFailures
    });
    
    networkMetrics.consecutiveFailures = 0;
    networkMetrics.consecutiveSuccesses = 0;
  } else if (networkMetrics.consecutiveSuccesses > 5) {
    // ì„±ê³µì´ ì—°ì†ë˜ë©´ ì²­í¬ í¬ê¸° ì¦ê°€ (Additive Increase)
    state.chunkSize = Math.min(MAX_CHUNK, state.chunkSize + 16 * 1024); // 16KBì”© ì¦ê°€
    
    console.log('[DEBUG Worker] Chunk size increased (AI):', {
      oldSize: oldChunkSize,
      newSize: state.chunkSize,
      reason: 'consecutive successes',
      successes: networkMetrics.consecutiveSuccesses
    });
    
    networkMetrics.consecutiveSuccesses = 0;
  }
  
  // ğŸš€ [RTT ê¸°ë°˜ ì¡°ì ˆ] RTTê°€ ë†’ìœ¼ë©´ ì‘ì€ ì²­í¬ ì‚¬ìš©
  if (networkMetrics.rtt > 200) { // 200ms ì´ìƒ
    const rttAdjustedSize = Math.max(MIN_CHUNK, Math.floor(64 * 1024 * (200 / networkMetrics.rtt)));
    if (rttAdjustedSize < state.chunkSize) {
      state.chunkSize = rttAdjustedSize;
      
      console.log('[DEBUG Worker] Chunk size adjusted for RTT:', {
        oldSize: oldChunkSize,
        newSize: state.chunkSize,
        rtt: networkMetrics.rtt,
        reason: 'high RTT adjustment'
      });
    }
  }
  
  // ğŸš€ [ì²˜ë¦¬ëŸ‰ ê¸°ë°˜ ì¡°ì ˆ] ì²˜ë¦¬ëŸ‰ì´ ë‚®ìœ¼ë©´ ì‘ì€ ì²­í¬ ì‚¬ìš©
  if (networkMetrics.throughput < 512 * 1024) { // 512KB/s ë¯¸ë§Œ
    const throughputAdjustedSize = Math.max(MIN_CHUNK, Math.floor(32 * 1024 * (networkMetrics.throughput / (512 * 1024))));
    if (throughputAdjustedSize < state.chunkSize) {
      state.chunkSize = throughputAdjustedSize;
      
      console.log('[DEBUG Worker] Chunk size adjusted for throughput:', {
        oldSize: oldChunkSize,
        newSize: state.chunkSize,
        throughput: networkMetrics.throughput,
        reason: 'low throughput adjustment'
      });
    }
  }
  
  networkMetrics.lastAdjustmentTime = now;
}

// ì›Œì»¤ ë¡œë“œ ì‹œ ì¤€ë¹„ ì‹ í˜¸
self.postMessage({ type: 'ready' });